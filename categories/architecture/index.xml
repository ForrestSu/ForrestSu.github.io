<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Architecture on 程序员的冷浪漫</title>
    <link>https://forrestsu.github.io/categories/architecture/</link>
    <description>Recent content in Architecture on 程序员的冷浪漫</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Fri, 08 May 2020 19:55:17 +0800</lastBuildDate>
    
	<atom:link href="https://forrestsu.github.io/categories/architecture/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Seastar 之 ready_future(3)</title>
      <link>https://forrestsu.github.io/posts/archi-seastar/seastar-ready-future/</link>
      <pubDate>Fri, 08 May 2020 19:55:17 +0800</pubDate>
      
      <guid>https://forrestsu.github.io/posts/archi-seastar/seastar-ready-future/</guid>
      <description>&lt;h2 id=&#34;1-什么是-ready_future&#34;&gt;1 什么是 ready_future&lt;/h2&gt;
&lt;p&gt;如果一个 future 在当下就已经有结果了，不必等到未来某个时刻，
我们把这个 future 称为 &lt;code&gt;ready_future&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;ready_future 的不同之处在于:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;(1) ready_future 可以单独使用，不必关联一个promise；&lt;br&gt;
(2) ready_future.then(lambda) 会把传入的lambda立即执行掉，
也就是说这个lambda没有机会放入任务队列；&lt;br&gt;
(3) 而not_ready_future每次执行，产生的新任务都会被放入任务队列，然后依此取出来执行。&lt;/p&gt;
&lt;/blockquote&gt;</description>
    </item>
    
    <item>
      <title>CPU Cache 架构</title>
      <link>https://forrestsu.github.io/posts/architecture-thinking/cpu-cache/</link>
      <pubDate>Wed, 08 Apr 2020 13:46:15 +0800</pubDate>
      
      <guid>https://forrestsu.github.io/posts/architecture-thinking/cpu-cache/</guid>
      <description>1 SMP (Symmetric Multi-Processor) 对称式多处理器 (SMP) 是一种计算机系统结构。
多处理器结构有两种：
 (l) 对称 —— 多个处理器都是等价的，线程每次受调度运行时都可以动态选择在任何一个处理器上运行。
(2) 非对称 —— 处理器的结构、能力、所处的部位、和作用都各不相同，不同的线程只能在特定的处理器上运行。
 通用 CPU 一般都是对称多处理器，生活中常见的CPU有 Intel Core 和 AMD 的CPU。
现代CPU朝着多核，多线程的方向发展。因为内存的存取速度远远跟不上CPU的执行速度， 所以引入了L1, L2,L3 级cache，L1 cache最小，分为指令cache和数据cache两种，两者都有32 Kbytes,他的存取速度是最接近于寄存器的。L2 cache一般有 256 Kbytes, L3 Cache 有 8 Mbytes。</description>
    </item>
    
    <item>
      <title>Seastar 之核间通信 (2)</title>
      <link>https://forrestsu.github.io/posts/archi-seastar/seastar-inter-core-communication/</link>
      <pubDate>Tue, 07 Apr 2020 23:06:23 +0800</pubDate>
      
      <guid>https://forrestsu.github.io/posts/archi-seastar/seastar-inter-core-communication/</guid>
      <description>&lt;h2 id=&#34;1-0核和任一个核通信&#34;&gt;1 0核和任一个核通信&lt;/h2&gt;
&lt;p&gt;Seastar 使用 eventfd 进行核间（线程间）通信，因为每个线程使用内核API &lt;code&gt;sched_set_affinity()&lt;/code&gt;，绑定一个 SMP 的 core，所以我们这里称之为&lt;strong&gt;核间通信&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;Seastar 创建了一个 N*N 的 event_fd 矩阵，每个单元格上两个event_fd，每一行event_fds由一个线程(Core)管理。&lt;br&gt;
也就是说每个线程的 epoll 上，一共需要侦听 2N 个 event_fd。&lt;/p&gt;
&lt;p&gt;示意图如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://forrestsu.github.io/images/seastar/inter-core-communication.png&#34; alt=&#34;f-p-inter-code-communication&#34;&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Seastar 之 future/promise 原理(1)</title>
      <link>https://forrestsu.github.io/posts/archi-seastar/seastar-future-promise/</link>
      <pubDate>Thu, 26 Mar 2020 23:11:26 +0800</pubDate>
      
      <guid>https://forrestsu.github.io/posts/archi-seastar/seastar-future-promise/</guid>
      <description>1 Preface Seastar (f-p-c) 属于Reactive编程的一个子集。
Seastar的性能源自 sharded，cooperative，non-blocking的微任务调度设计， 而 f-p-c 是将 task 送入调度程序的一种更友好的方式。
Seastar引入了 future/promise, 把面向 callback 编程变成了面向future/promise编程， 将以前的回调代码包装在 lambda_task 中，然后交给future调度。
(1) promise 表示一个承诺，这个承诺将在未来某一个时刻兑现;
(2) promise可以立即返回一个future, 拿到future的调用者可以在未来某个时刻调用future.get()兑现承诺。
为了满足复杂的异步编程需要，Seastar重新实现了一些有别于标准库中的数据结构，因为像 thread safe这样的要求是无需考虑的。这里主要讨论的是Seastar实现的 future/promise。</description>
    </item>
    
    <item>
      <title>异步编程之 CPS</title>
      <link>https://forrestsu.github.io/posts/architecture-thinking/asynchronous-programming-cps/</link>
      <pubDate>Fri, 20 Apr 2018 22:44:50 +0800</pubDate>
      
      <guid>https://forrestsu.github.io/posts/architecture-thinking/asynchronous-programming-cps/</guid>
      <description>1 Preface 后继传递风格(continuation-passing style CPS wiki) 具体解释请阅读wiki。
CPS 最初在1970年代作为一种编程风格出现，主要用于函数式编程； 在1980年代到1990年代期间，其作为高级编程语言的编译器的一种中间表达形式开始崭露头角。
现在，CPS作为非阻塞系统（通常是分布式）的一种编程风格被再次发掘出来。
1.1 CPS in Haskell 我们使用Haskell 实现勾股定理(Pythagorean theorem) 计算斜边的长度。 传统的实现如下：
1 2 3 4 5 6 7 8  square :: Double -&amp;gt; Double square x = x * x add :: Double -&amp;gt; Double -&amp;gt; Double add x y = x + y pythagorean :: Double -&amp;gt; Double -&amp;gt; Double pythagorean x y = sqrt (add (square x) (square y))   然后我们将其改造成 CPS 的方式，如下：</description>
    </item>
    
    <item>
      <title>Seastar 入门</title>
      <link>https://forrestsu.github.io/posts/archi-seastar/seastar-started/</link>
      <pubDate>Tue, 27 Feb 2018 14:00:04 +0800</pubDate>
      
      <guid>https://forrestsu.github.io/posts/archi-seastar/seastar-started/</guid>
      <description>1 what is Seastar 这篇文章将介绍一下 Seastar : 一个在现在多核机器上编写高效复杂的服务器应用程序的 C++ 库。
有些框架非常高效，但只允许构建简单的应用程序（eg: DPDK 允许单独处理数据包的应用程序）, 而其他框架则允许构建极其复杂的应用程序，代价是运行时效率。Seastar 是我们尝试获得两全其美的方法：创建一个允许构建高度复杂的服务器应用程序并实现最佳性能的库。
2 起源 Seastar 的灵感和首例使用案例是ScyllaDB，重写了Apache Cassandra，Cassandra 是一个分厂复杂的应用，同时通过 Seastar，我们能够重新实现吞吐量提高10倍，以及显着降低和更一致的延迟。 Seastar提供了一个完整的异步编程框架，它使用两个概念 - 期货和延续 - 统一表示和处理每种类型的异步事件，包括网络I/O，磁盘 I/O 以及其他事件的复杂组合。
由于现代多核和多插槽机器在核心之间共享数据（原子指令，高速缓存行反弹和内存隔离）具有陡峭的惩罚，Seastar程序使用无共享编程模型，即可用内存在内核之间分配，每个内核都在其内存部分进行数据处理，内核之间的通信通过显式消息传递进行（当然，这本身就是使用SMP的共享内存硬件发生的）。</description>
    </item>
    
    <item>
      <title>Thinking coroutine thread async</title>
      <link>https://forrestsu.github.io/posts/architecture-thinking/thinking-coroutine-thread-async/</link>
      <pubDate>Thu, 08 Feb 2018 22:32:16 +0800</pubDate>
      
      <guid>https://forrestsu.github.io/posts/architecture-thinking/thinking-coroutine-thread-async/</guid>
      <description>从最开始的C语言，同步编程，后来工作了，慢慢开始写异步代码，逐渐有了一些自己的思考和想法。同样都是写业务代码，如何写出高性能，易维护，简洁的 code？ 现有的编程框架有哪些局限性？ 我们来回顾下，业务代码中一个常见的模型：生产者消费者(围笑)! 我们来看下生产者消费者最简单的情况： 一个生产者线程，一个消费者线程，一个共享的queue，为了防止并发冲突，再加上 lock/semaphore 。 随着业务接口慢慢增多，一个接口每次都搞 2个线程，线程数和queue 也线性增加，写代码就慢慢变成了 copy/paste。总得想点什么办法吧！ 于是搞个异步, 我们就写自己数据处理函数。
异步编程</description>
    </item>
    
    <item>
      <title>Thinking micro-service Architecture</title>
      <link>https://forrestsu.github.io/posts/architecture-thinking/thinking-micro-service-architecture/</link>
      <pubDate>Mon, 15 May 2017 14:41:51 +0800</pubDate>
      
      <guid>https://forrestsu.github.io/posts/architecture-thinking/thinking-micro-service-architecture/</guid>
      <description>前言 　目前微服务架构，基本都是通过消息系统来进行Node与Node之间的通信，开完成数据交互的。 目前常用的解决方案: 消息MQ: ZeroMQ、RabbitMQ 数据协议： protobuf、json 数据持久化： Redis、MongoDB 框架： Libuv
Analysis Advantage Analysis： zeroMQ</description>
    </item>
    
  </channel>
</rss>